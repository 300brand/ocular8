#!/usr/bin/env python3
import argparse
import bson
import datetime
import feedparser
import pymongo
import time
import urllib.request

def process(db, feed, nsq):
	etag = feed.get('etag', None)
	modified = feed.get('lastmodified', None)
	doc = feedparser.parse(feed['url'], etag=etag, modified=modified)

	status = doc.get('status', 500)

	print(feed['_id'], 'STATUS', status)

	nextdownload = None
	if doc['bozo'] == 0:
		nextdownload = datetime.datetime.utcnow() + datetime.timedelta(hours=1)

	sets = {
		'bozo':         doc['bozo'],
		'etag':         doc.get('etag', None),
		'lastmodified': doc.get('modified', None),
		'laststatus':   status,
		'lastdownload': datetime.datetime.utcnow(),
		'nextdownload': nextdownload
	}
	if 'updated_parsed' in doc and doc['updated_parsed'] is not None:
		t = datetime.datetime.utcfromtimestamp(time.mktime(doc['updated_parsed']))
		sets['updated'] = t
	if status == 301:
		sets['originalurl'] = feed['url']
		sets['url'] = doc['href']

	update = {
		'$set': sets,
		'$inc': {
			'downloads': 1
		}
	}

	db.feeds.update({ '_id': feed['_id'] }, update)

	if status in [ 304, 410, 500 ]:
		return

	ids = []
	for entry in doc.entries:
		if 'link' not in entry:
			print(feed['_id'], 'NO ENTRY LINK')
			continue

		if db.entries.find_one({ 'link': entry['link'] }) is not None:
			print(feed['_id'], 'NONUNIQUE', entry['link'])
			return

		entry['_id'] = bson.objectid.ObjectId()
		entry['feedid'] = feed['_id']
		entry['pubid'] = feed['pubid']

		db.entries.insert(entry)
		ids.append(str(entry['_id']))

	payload = ('\n'.join(ids) + '\n').encode('utf-8')
	urllib.request.urlopen("%s/mpub?topic=entry.id.download" % nsq, data=payload)
	print(feed['_id'], 'SENT', len(ids))

def main():
	parser = argparse.ArgumentParser(description='Download feed and push new URLs into next queue')
	parser.add_argument('-mongo', help='MongoDB connection string', default='mongodb://localhost:27017/ocular8')
	parser.add_argument('-nsqdhttp', help='NSQd HTTP address', default='http://localhost:4151')
	parser.add_argument('id', help='Feed ObjectId', nargs='+')
	args = parser.parse_args()

	db = pymongo.MongoClient(args.mongo).get_default_database()

	bson_ids = [ bson.objectid.ObjectId(id) for id in args.id ]
	feeds = db.feeds.find({ '_id': { '$in': bson_ids } })
	for feed in feeds:
		process(db, feed, args.nsqdhttp)

if __name__ == '__main__':
	main()
