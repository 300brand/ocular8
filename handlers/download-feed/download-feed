#!/usr/bin/env python
import argparse
import bson
import bson.json_util
import datetime
import feedparser
import pymongo
import time
import urllib.request

def process_feed(db, feed, nsq):
	etag = feed.get('etag', None)
	modified = feed.get('lastmodified', None)
	doc = feedparser.parse(feed['url'], etag=etag, modified=modified)

	status = doc.get('status', 500)

	print(feed['_id'], 'STATUS', status)

	update = {
		'bozo':         doc['bozo'],
		'etag':         doc.get('etag', None),
		'lastmodified': doc.get('modified', None),
		'laststatus':   status,
		'lastdownload': datetime.datetime.utcnow(),
		'nextdownload': datetime.datetime.utcnow() + datetime.timedelta(hours=1)
	}
	if 'updated' in doc:
		t = datetime.datetime.utcfromtimestamp(time.mktime(doc['updated_parsed']))
		update['updated'] = t
	if status == 301:
		update['originalurl'] = feed['url']
		update['url'] = doc['href']

	db.feeds.update({ '_id': feed['_id'] }, { '$set': update })

	if status in [ 304, 410, 500 ]:
		return

	items = []
	for entry in doc.entries:
		published = entry.get('published_parsed', None)
		if published is not None:
			published = datetime.datetime.utcfromtimestamp(time.mktime(published))

		data = {
			'feedid':    feed['_id'],
			'author':    entry.get('author', None),
			'published': published,
			'title':     entry.get('title', None),
			'url':       entry['link']
		}

		items.append(bson.json_util.dumps(data))

	payload_str = '\n'.join(items) + '\n'
	payload = payload_str.encode('utf-8')
	urllib.request.urlopen("%s/mpub?topic=article.url.download" % nsq, data=payload)
	print(feed['_id'], 'SENT', len(items))

def main():
	parser = argparse.ArgumentParser(description='Download feed and push new URLs into next queue')
	parser.add_argument('-mongo', help='MongoDB connection string', default='mongodb://localhost:27017/ocular8')
	parser.add_argument('-nsqdhttp', help='NSQd HTTP address', default='http://localhost:4151')
	parser.add_argument('id', help='Feed ObjectId', nargs='+')
	args = parser.parse_args()

	db = pymongo.MongoClient(args.mongo).get_default_database()
	db.articles.ensure_index('url', unique=True)

	bson_ids = [ bson.objectid.ObjectId(id) for id in args.id ]
	feeds = db.feeds.find({ '_id': { '$in': bson_ids } })

	for feed in feeds:
		process_feed(db, feed, args.nsqdhttp)

if __name__ == '__main__':
	main()
